# üìö U-Net Instance Segmentation Examples

This directory contains practical examples and tutorials for using U-Net for instance segmentation tasks.

## üìÅ Directory Structure

```
examples/
‚îú‚îÄ‚îÄ basic/              # Basic U-Net usage
‚îú‚îÄ‚îÄ training/           # Training scripts
‚îú‚îÄ‚îÄ inference/          # Inference and prediction
‚îú‚îÄ‚îÄ medical/            # Medical imaging applications
‚îî‚îÄ‚îÄ mobile/             # Mobile deployment
```

## üöÄ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Or install specific packages
pip install torch torchvision segmentation-models-pytorch
pip install albumentations opencv-python matplotlib
```

## üìñ Examples

### 1. Basic Usage (`basic/`)

#### `simple_unet.py`
Learn the fundamentals of U-Net:
- Creating a U-Net model
- Model information and parameters
- Running inference
- Available encoder backbones

**Run:**
```bash
python examples/basic/simple_unet.py
```

**What you'll learn:**
- ‚úì How to initialize a U-Net model
- ‚úì How to check model size and parameters
- ‚úì Available pretrained encoders
- ‚úì Basic inference workflow

---

### 2. Training (`training/`)

#### `train_unet.py`
Complete training pipeline:
- Custom dataset creation
- Data augmentation strategies
- Training loop with validation
- Checkpoint saving
- Metrics calculation (IoU, F1, Dice)

**Run:**
```bash
python examples/training/train_unet.py
```

**Features:**
- üî• PyTorch training loop
- üìä Real-time metrics (IoU, Dice loss)
- üíæ Automatic checkpoint saving
- üîÑ Learning rate scheduling
- üé® Data augmentation with Albumentations

**Customization:**
```python
# Change hyperparameters
BATCH_SIZE = 16
NUM_EPOCHS = 100
LEARNING_RATE = 1e-3

# Change encoder
model = smp.Unet(
    encoder_name="efficientnet-b7",
    encoder_weights="imagenet"
)

# Custom loss function
from segmentation_models_pytorch.losses import DiceLoss, FocalLoss
criterion = DiceLoss(mode='binary') + FocalLoss(mode='binary')
```

---

### 3. Inference (`inference/`)

#### `watershed_instance_seg.py`
Instance segmentation using U-Net + Watershed:
- Semantic segmentation with U-Net
- Watershed algorithm for instance separation
- Post-processing and refinement
- Instance property extraction
- Visualization

**Run:**
```bash
python examples/inference/watershed_instance_seg.py
```

**Pipeline:**
1. **U-Net** ‚Üí Semantic segmentation mask
2. **Watershed** ‚Üí Separate overlapping instances
3. **Post-processing** ‚Üí Remove noise and small objects
4. **Extraction** ‚Üí Get instance properties (area, bbox, centroid)

**Key Features:**
- üîç Instance separation for overlapping objects
- üìè Extract bounding boxes, areas, centroids
- üé® Colored visualization of instances
- ‚öôÔ∏è Configurable parameters (min_distance, min_size)

**Usage Example:**
```python
from watershed_instance_seg import InstanceSegmentationPipeline

# Initialize pipeline
pipeline = InstanceSegmentationPipeline(model_path='best_model.pth')

# Load image
import cv2
image = cv2.imread('input.jpg')

# Run instance segmentation
instance_mask, properties = pipeline.predict(
    image,
    min_distance=20,    # Minimum distance between instances
    min_size=100        # Minimum instance size (pixels)
)

# Visualize
pipeline.visualize_results(image, instance_mask, properties)
```

---

### 4. Medical Imaging (`medical/`)

#### `medical_segmentation.py`
Specialized medical imaging applications:
- Cell nuclei segmentation
- Tumor segmentation (CT/MRI)
- Medical-specific preprocessing
- Clinical metrics (Dice, IoU, Sensitivity, Specificity)
- Hausdorff distance calculation

**Run:**
```bash
python examples/medical/medical_segmentation.py
```

**Supported Tasks:**
- üî¨ Cell nuclei detection (histopathology)
- ü´Ä Organ segmentation
- üß† Tumor segmentation (brain, liver, kidney, pancreas)

**Medical Metrics:**
- Dice Coefficient (F1-Score)
- IoU (Jaccard Index)
- Sensitivity (Recall)
- Specificity
- Precision
- Hausdorff Distance

**Example:**
```python
from medical_segmentation import MedicalUNet

# Create model for cell nuclei
model = MedicalUNet(task_type='cell_nuclei', encoder='efficientnet-b4')

# Segment
mask = model.segment(histology_image)

# Post-process
mask = model.post_process_cells(mask)

# Calculate metrics
metrics = model.calculate_medical_metrics(pred_mask, ground_truth)
print(f"Dice: {metrics['dice']:.4f}")
print(f"IoU: {metrics['iou']:.4f}")
```

---

### 5. Mobile Deployment (`mobile/`)

#### `mobile_deployment.py`
Export and optimize models for mobile devices:
- Export to ONNX
- Export to TorchScript (mobile-optimized)
- Model quantization
- Inference benchmarking
- Deployment guides (iOS, Android, Web)

**Run:**
```bash
python examples/mobile/mobile_deployment.py
```

**Export Formats:**
- üì± **ONNX** - Universal format for iOS (Core ML), Android, Web
- üî• **TorchScript** - Optimized for PyTorch Mobile
- ‚ö° **Quantized** - Reduced size and faster inference

**Features:**
- Model size reduction (up to 75%)
- Inference speed benchmarking
- Mobile-optimized architectures (MobileNet, EfficientNet-B0)
- Deployment guides for all platforms

**Platform-Specific Deployment:**

**iOS (Core ML):**
```python
from mobile_deployment import MobileUNet

model = MobileUNet(encoder='mobilenet_v2')
model.export_to_onnx('unet_mobile.onnx')

# Convert to Core ML (requires coremltools)
import coremltools as ct
mlmodel = ct.converters.onnx.convert(model='unet_mobile.onnx')
mlmodel.save('UNet.mlmodel')
```

**Android (TensorFlow Lite):**
```python
# Export to ONNX first
model.export_to_onnx('unet_mobile.onnx')

# Convert ONNX ‚Üí TensorFlow ‚Üí TFLite
# (requires onnx-tf and tensorflow)
```

**Web (ONNX.js):**
```javascript
// Load model in browser
const session = await ort.InferenceSession.create('unet_mobile.onnx');
const results = await session.run(feeds);
```

---

## üéØ Use Case Examples

### Cell Segmentation
```bash
# Run cell nuclei segmentation
python examples/medical/medical_segmentation.py

# Expected output:
# - Segmented nuclei with individual labels
# - Instance count and properties
# - Visualization with bounding boxes
```

### Building Instance Segmentation (Satellite Imagery)
```python
# Load U-Net trained on building dataset
from watershed_instance_seg import InstanceSegmentationPipeline

pipeline = InstanceSegmentationPipeline(model_path='building_unet.pth')
instance_mask, properties = pipeline.predict(satellite_image)

# Extract building footprints
for prop in properties:
    area_m2 = prop['area'] * pixel_to_meter_ratio**2
    print(f"Building {prop['label']}: {area_m2:.2f} m¬≤")
```

### Real-time Inference
```python
# Use lightweight model for real-time processing
import cv2
from mobile_deployment import ONNXInference

# Initialize ONNX runtime
inference = ONNXInference('unet_mobile_quantized.onnx')

# Process video stream
cap = cv2.VideoCapture(0)
while True:
    ret, frame = cap.read()
    mask = inference.predict(frame)
    # Display mask overlay
    cv2.imshow('Segmentation', mask * 255)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
```

---

## üìä Performance Benchmarks

### Model Sizes

| Encoder | Parameters | Model Size | Inference Time (GPU) |
|---------|------------|------------|----------------------|
| ResNet34 | 24.4M | 93 MB | 15 ms |
| EfficientNet-B4 | 19.3M | 74 MB | 22 ms |
| MobileNetV2 | 9.7M | 37 MB | 12 ms |
| EfficientNet-B0 | 7.8M | 30 MB | 10 ms |

### Instance Segmentation Performance

| Method | Dataset | mAP | IoU | FPS |
|--------|---------|-----|-----|-----|
| U-Net + Watershed | Cells | 0.85 | 0.78 | 25 |
| IAUNet | COCO | 0.42 | 0.61 | 18 |
| Mask R-CNN | COCO | 0.38 | 0.58 | 12 |

---

## üõ†Ô∏è Troubleshooting

### Common Issues

**1. CUDA out of memory**
```python
# Reduce batch size
BATCH_SIZE = 4  # Instead of 16

# Or reduce image resolution
input_size = (256, 256)  # Instead of (512, 512)
```

**2. Import errors**
```bash
# Install missing dependencies
pip install segmentation-models-pytorch albumentations
```

**3. Slow training**
```python
# Enable mixed precision training
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    outputs = model(images)
    loss = criterion(outputs, masks)
```

**4. Poor segmentation results**
- Check data augmentation (might be too aggressive)
- Verify ground truth masks are correct
- Increase training epochs
- Try different loss functions (Dice + BCE)
- Use pretrained encoders

---

## üìö Additional Resources

### Tutorials
- [U-Net Architecture Explained](https://arxiv.org/abs/1505.04597)
- [Instance Segmentation Guide](https://paperswithcode.com/task/instance-segmentation)
- [PyTorch Segmentation Tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)

### Datasets
- [COCO 2017](https://cocodataset.org/) - General instance segmentation
- [Cityscapes](https://www.cityscapes-dataset.com/) - Urban driving scenes
- [Data Science Bowl 2018](https://www.kaggle.com/c/data-science-bowl-2018) - Cell nuclei
- [BraTS](https://www.med.upenn.edu/cbica/brats2020/) - Brain tumor segmentation

### Pretrained Models
- [Segmentation Models PyTorch](https://github.com/qubvel-org/segmentation_models.pytorch)
- [PyTorch Hub](https://pytorch.org/hub/)
- [Model Zoo](https://modelzoo.co/)

---

## ü§ù Contributing

Have a new example or improvement? Please see [CONTRIBUTING.md](../CONTRIBUTING.md) for guidelines.

---

## üìù License

All examples are released under the MIT License. See [LICENSE](../LICENSE) for details.

---

## üôè Acknowledgments

- **Segmentation Models PyTorch** - For the excellent library
- **PyTorch Community** - For tutorials and support
- **Research Community** - For papers and implementations

---

<div align="center">

**Happy Segmenting! üé®**

[‚¨Ü Back to Main README](../README.md)

</div>
